{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zpFqk0dsCndv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANDREAS\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.environ.get(\"RESEARCH_DATA_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we specify the the date range of the datasets that will be used and the test size, the number of folds for the cross validation and the grid of ragularization hyperparameters that we will use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M3AmheKGBmfe"
   },
   "outputs": [],
   "source": [
    "# Define the start and end dates for the data range\n",
    "start_date = '1985-01-31'\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "# Specify the proportion of test data (e.g., 10%)\n",
    "test_data_size = 0.2\n",
    "\n",
    "# Set the number of splits for K-Fold Cross Validation\n",
    "KFold_split = 5\n",
    "\n",
    "# Specify a range of alpha values for Ridge regression\n",
    "alphas = [10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3, 10**4, 10**5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we upload our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MhbNO9EuIJxx"
   },
   "outputs": [],
   "source": [
    "# UPLOAD MONTHLY DATA\n",
    "X_mef_monthly = pd.read_csv(f'{DATA_PATH}/processed/mef_monthly_data_processed.csv')\n",
    "X_mai_monthly = pd.read_csv(f'{DATA_PATH}/processed/mai_monthly_data_processed.csv')\n",
    "y_mkt_monthly = pd.read_csv(f'{DATA_PATH}/processed/mkt_monthly_data_processed.csv')\n",
    "\n",
    "X_mef_monthly['date'] = pd.to_datetime(X_mef_monthly['date'])\n",
    "X_mai_monthly['date'] = pd.to_datetime(X_mai_monthly['date'])\n",
    "y_mkt_monthly['date'] = pd.to_datetime(y_mkt_monthly['date'])\n",
    "\n",
    "X_mef_monthly = X_mef_monthly[(X_mef_monthly['date'] >= start_date) & (X_mef_monthly['date'] <= end_date)]\n",
    "X_mai_monthly = X_mai_monthly[(X_mai_monthly['date'] >= start_date) & (X_mai_monthly['date'] <= end_date)]\n",
    "y_mkt_monthly = y_mkt_monthly[(y_mkt_monthly['date'] >= start_date) & (y_mkt_monthly['date'] <= end_date)]\n",
    "\n",
    "# Drop the 'date' column from each dataset\n",
    "X_mef_monthly = X_mef_monthly.drop('date', axis=1)\n",
    "X_mai_monthly = X_mai_monthly.drop('date', axis=1)\n",
    "y_mkt_monthly = y_mkt_monthly.drop('date', axis=1)\n",
    "\n",
    "X_mef_monthly = X_mef_monthly.values\n",
    "X_mai_monthly = X_mai_monthly.values\n",
    "y_mkt_monthly = y_mkt_monthly.values\n",
    "\n",
    "# UPLOAD DAILY DATA\n",
    "X_mai_daily = pd.read_csv(f'{DATA_PATH}/processed/mai_daily_data_processed.csv')\n",
    "y_mkt_daily = pd.read_csv(f'{DATA_PATH}/processed/mkt_daily_data_processed.csv')\n",
    "\n",
    "X_mai_daily['date'] = pd.to_datetime(X_mai_daily['date'])\n",
    "y_mkt_daily['date'] = pd.to_datetime(y_mkt_daily['date'])\n",
    "\n",
    "X_mai_daily = X_mai_daily[(X_mai_daily['date'] >= start_date) & (X_mai_daily['date'] <= end_date)]\n",
    "y_mkt_daily = y_mkt_daily[(y_mkt_daily['date'] >= start_date) & (y_mkt_daily['date'] <= end_date)]\n",
    "\n",
    "# Drop the 'date' column from each dataset\n",
    "X_mai_daily = X_mai_daily.drop('date', axis=1)\n",
    "y_mkt_daily = y_mkt_daily.drop('date', axis=1)\n",
    "\n",
    "X_mai_daily = X_mai_daily.values\n",
    "y_mkt_daily = y_mkt_daily.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define necessary functions for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oWPidNaOAwys"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, train_size, indices):\n",
    "    # Split indices into train and test indices\n",
    "    train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "    # Split data based on the indices\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "euuWFg1kA5LL"
   },
   "outputs": [],
   "source": [
    "def find_optimal_ridge_hyperparameters(X_train, y_train, alphas, KFold_split):\n",
    "    optimal_degree = None\n",
    "    optimal_alpha = None\n",
    "    minimal_mse = float('inf')\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        kf = KFold(n_splits=KFold_split)\n",
    "        mse_arr = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X_train_std):\n",
    "            X_train_n, y_train_n = X_train_std[train_index], y_train[train_index]\n",
    "            X_train_v, y_train_v = X_train_std[test_index], y_train[test_index]\n",
    "\n",
    "            # Train Ridge regression\n",
    "            ridge = Ridge(alpha=alpha)\n",
    "            ridge.fit(X_train_n, y_train_n)\n",
    "\n",
    "            # Predict and calculate MSE on the validation set\n",
    "            y_pred = ridge.predict(X_train_v)\n",
    "            mse = mean_squared_error(y_train_v, y_pred)\n",
    "            mse_arr.append(mse)\n",
    "\n",
    "        # Calculate the average MSE across KFold splits\n",
    "        avg_mse = np.mean(mse_arr)\n",
    "\n",
    "        # Update optimal hyperparameters if the current setup is better\n",
    "        if avg_mse < minimal_mse:\n",
    "            optimal_alpha = alpha\n",
    "            minimal_mse = avg_mse\n",
    "\n",
    "    return optimal_alpha, minimal_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "35YRgMrHDO44"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_ridge(X_train, y_train, X_test, y_test, alpha):\n",
    "    # Train Ridge regression on the entire training set\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    #print(f\" MEF Coefficients: {ridge.coef_}\")\n",
    "\n",
    "\n",
    "    # Predict on the training and test sets\n",
    "    y_pred_train = ridge.predict(X_train)\n",
    "    y_pred_test = ridge.predict(X_test)\n",
    "\n",
    "    # Calculate and print MSE for the training and test sets\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    return mse_train, mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tJlxSRo3ThGE"
   },
   "outputs": [],
   "source": [
    "def predict_with_ridge(model, scaler, new_X):\n",
    "    # Standardize the new_X using the same scaler used for training\n",
    "    new_X_std = scaler.transform(new_X.reshape(1, -1))\n",
    "\n",
    "    # Predict the target value using the trained Ridge model\n",
    "    predicted_y = model.predict(new_X_std)\n",
    "\n",
    "    return predicted_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our model for the monthly data. Since the datasets are small, in order to get more robust results, we train the models 10 times with a different train-test split every time and report the average RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kmi-PRvuVEzt",
    "outputId": "4853739c-ce2d-4136-8eda-a7277d3150d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEF Linear Predictor\n",
      "Average Train RMSE for MEF data: 50.12737785435657\n",
      "Average Test RMSE for MEF data: 53.119012813651906\n",
      "\n",
      "MAI Linear Predictor\n",
      "Average Train RMSE for MAI data: 50.44399701899028\n",
      "Average Test RMSE for MAI data: 53.21590645237683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating Ridge model: MEF\n",
    "\n",
    "MEF_errors_train = []\n",
    "MEF_errors_test = []\n",
    "MAI_errors_train = []\n",
    "MAI_errors_test = []\n",
    " \n",
    "train_size = int((1-test_data_size) * X_mef_monthly.shape[0])\n",
    "indices = np.random.permutation(X_mef_monthly.shape[0])\n",
    "\n",
    "for i in range(10):\n",
    "    # Split data into training and test sets\n",
    "    np.random.shuffle(indices)\n",
    "    X_train_mef, y_train_mef, X_test_mef, y_test_mef = split_data(X_mef_monthly, y_mkt_monthly, train_size, indices)\n",
    "    X_train_mai, y_train_mai, X_test_mai, y_test_mai = split_data(X_mai_monthly, y_mkt_monthly, train_size, indices)\n",
    "\n",
    "    # Standardize both training and test data using a scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std_mef = scaler.fit_transform(X_train_mef)\n",
    "    X_test_std_mef = scaler.transform(X_test_mef)  \n",
    "    X_train_std_mai = scaler.fit_transform(X_train_mai)\n",
    "    X_test_std_mai = scaler.transform(X_test_mai)\n",
    "\n",
    "    # Find optimal alpha using cross-validation\n",
    "    optimal_alpha_mef, minimal_mse_mef = find_optimal_ridge_hyperparameters(X_train_std_mef, y_train_mef, alphas, KFold_split)    \n",
    "    optimal_alpha_mai, minimal_mse_mai = find_optimal_ridge_hyperparameters(X_train_std_mai, y_train_mai, alphas, KFold_split)\n",
    "\n",
    "    minimal_rmse_mef = minimal_mse_mef**(1/2)\n",
    "    #print(f\"Optimal alpha for MEF data: {optimal_alpha_mef}, Minimal MSE: {minimal_rmse_mef}\")    \n",
    "    minimal_rmse_mai = minimal_mse_mai**(1/2)\n",
    "    #print(f\"Optimal alpha for MAI data: {optimal_alpha_mai}, Minimal MSE: {minimal_rmse_mai}\")\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    mse_train_mef, mse_test_mef = train_and_evaluate_ridge(X_train_std_mef, y_train_mef, X_test_std_mef, y_test_mef, optimal_alpha_mef)\n",
    "    rmse_train_mef = mse_train_mef**(1/2)\n",
    "    rmse_test_mef = mse_test_mef**(1/2)\n",
    "    \n",
    "    MEF_errors_train.append(rmse_train_mef)\n",
    "    MEF_errors_test.append(rmse_test_mef)\n",
    "\n",
    "    mse_train_mai, mse_test_mai = train_and_evaluate_ridge(X_train_std_mai, y_train_mai, X_test_std_mai, y_test_mai, optimal_alpha_mai)\n",
    "    rmse_train_mai = mse_train_mai**(1/2)\n",
    "    rmse_test_mai = mse_test_mai**(1/2)\n",
    "    \n",
    "    MAI_errors_train.append(rmse_train_mai)\n",
    "    MAI_errors_test.append(rmse_test_mai)\n",
    "\n",
    "    # Save the trained model and scaler for later use\n",
    "    ridge_scaler = scaler\n",
    "\n",
    "    \n",
    "MEF_avg_rmse_train = sum(MEF_errors_train) / len(MEF_errors_train)   \n",
    "MEF_avg_rmse_test = sum(MEF_errors_test) / len(MEF_errors_test)\n",
    "print('MEF Linear Predictor')\n",
    "print(f\"Average Train RMSE for MEF data: {MEF_avg_rmse_train}\")\n",
    "print(f\"Average Test RMSE for MEF data: {MEF_avg_rmse_test}\")\n",
    "print(\"\")\n",
    "\n",
    "MAI_avg_rmse_train = sum(MAI_errors_train) / len(MAI_errors_train)\n",
    "MAI_avg_rmse_test = sum(MAI_errors_test) / len(MAI_errors_test)\n",
    "print('MAI Linear Predictor')\n",
    "print(f\"Average Train RMSE for MAI data: {MAI_avg_rmse_train}\")\n",
    "print(f\"Average Test RMSE for MAI data: {MAI_avg_rmse_test}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the same for the daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for daily data: 54.152248148555564\n",
      "Test RMSE for daily data: 54.33290483547013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_size = int((1-test_data_size) * X_mai_daily.shape[0])\n",
    "indices = np.random.permutation(X_mai_daily.shape[0])\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "X_train, y_train, X_test, y_test = split_data(X_mai_daily, y_mkt_daily, train_size, indices)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)  \n",
    "\n",
    "optimal_alpha, minimal_mse = find_optimal_ridge_hyperparameters(X_train_std, y_train, alphas, KFold_split)    \n",
    "\n",
    "minimal_rmse = minimal_mse**(1/2)\n",
    "   \n",
    "mse_train, mse_test = train_and_evaluate_ridge(X_train_std, y_train, X_test_std, y_test, optimal_alpha)\n",
    "rmse_train = mse_train**(1/2)\n",
    "rmse_test = mse_test**(1/2)\n",
    "\n",
    "print(f\"Train RMSE for daily data: {rmse_train}\")\n",
    "print(f\"Test RMSE for daily data: {rmse_test}\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
